# First Proof: Solution Iterations via Open-Source LLMs

This repository accompanies the paper

> **First Proof: Solution Iterations via Open-Source LLMs**  
> Akilan Sankaran and Param Thakkar, 2026

and documents a systematic empirical study of *‚Äúfirst proof‚Äù* attempts generated by large language models (LLMs) on research-level and graduate-level mathematics problems.

The project responds directly to the **First Proof** challenge introduced by Abouzaid et al. (2026), with a focus not merely on correctness, but on *procedural structure, scaffolding, intuition formation, and comparative reasoning behavior* across models.

---

## üìå Overview

Modern LLMs increasingly exhibit nontrivial mathematical reasoning abilities, yet the nature and limits of these capabilities remain poorly understood. This project evaluates whether such models can produce *plausible first proofs* of advanced mathematical statements without fine-tuning or tool augmentation.

We study:
- Zero-shot and minimal one-shot proof attempts
- Proof scaffolding and reduction strategies
- Model-specific proof styles and failure modes
- Comparative reasoning across frontier LLM paradigms

All proofs are presented **unedited**, preserving model output fidelity.

---

## üß† Models Evaluated

We evaluate state-of-the-art general-purpose LLMs, including:

- **Gemini 3 Pro** (Google DeepMind)
- **Claude Sonnet 4.5** (Anthropic)

No fine-tuning, retrieval augmentation, or symbolic solvers were used.

---

## üìö Problem Domains

The curated problem set spans active research areas, including:

- Stochastic quantization  
- Automorphic and representation theory  
- Integrable probability  
- Finite free probability  
- Equivariant homotopy theory  
- Spectral graph theory  
- Geometric topology  

Problems were drawn from the *First Proof* corpus and are representative of research-level difficulty.

---

## üß™ Experimental Protocol

### Prompting Regime

All interactions with each model were restricted to the following prompts:

1. **Initial zero-shot proof prompt**
2. **Minimal correctness check prompt (if necessary)**
3. **Post-hoc reflection prompt** (strategic explanation only)

No further dialogue was permitted.

### Key Constraints

- No chain-of-thought elicitation beyond model-generated exposition
- No external tools, code execution, or symbolic systems
- Proofs evaluated as mathematical artifacts, not just answers
